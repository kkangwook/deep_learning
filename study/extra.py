딥러닝: 층 마다 선형방정식을 통과시켜 결과를 출력
  딥러닝의 선형방정식: 가중치와 절편을 랜덤하게 초기화 한 다음 에포크를 반복하면서 경사하강법으로 최적의 가중치와 절편을 찾음 

뉴련의 개수: 선형방정식의 개수
->은닉층의 뉴런개수가 100개면 100개의 선형방정식을 준비해 입력층의 모든 값을 입력층의모든값에 대응되는 가중치를 가진 선형방정식에 대입해 100개의 z값 출력-> 시그모이드나 렐루로 z값 변형
->출력층의 뉴런개수를 10개로 하면 10개의 선형방정식을 준비해 100개의 모든 z값을 하나 하나의 선형방정식에(100개의 가중치를 가짐) 넣어 10개의 z값으로 출력
-> 이후 소프트맥스 활성화 함수를 이용해 하나의 예측값으로 출력 

소프트맥스 함수: 모든 z값을 모아 하나의 결과를 출력(사실 하나의 결과는 아니고 각 클래스==z개수 별 확률 출력/이 확률의 전체합이 1)  
렐루함수: 각 z별 하나의 z에 렐루값이 적용돼 z개수만큼 출력 EX)z값이 10개면 렐루값도 10개 (z가 0보다 작으면 0, 0보다 크면 z로 변환)
시그모이드 함수: 얘도 렐루처럼 작용(2개가 들어와야한다고 착각할 수 있지만 사실 이진 분류에서도 시그모이드 함수는 하나에만 적용됐고 나머지는 1-a를 했었음) -> 0~1의 값으로 변환
