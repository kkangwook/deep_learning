딥러닝: 층 마다 선형방정식을 통과시켜 결과를 출력
  딥러닝의 선형방정식: 가중치와 절편을 랜덤하게 초기화 한 다음 에포크를 반복하면서 경사하강법으로 최적의 가중치와 절편을 찾음 

뉴련의 개수: 선형방정식의 개수
->은닉층의 뉴런개수가 100개면 100개의 선형방정식을 준비해 입력층의 모든 값을 입력층의모든값에 대응되는 가중치를 가진 선형방정식에 대입해 100개의 z값 출력-> 시그모이드나 렐루로 z값 변형
->출력층의 뉴런개수를 10개로 하면 10개의 선형방정식을 준비해 100개의 모든 z값을 하나 하나의 선형방정식에(100개의 가중치를 가짐) 넣어 10개의 z값으로 출력
-> 이후 소프트맥스 활성화 함수를 이용해 하나의 예측값으로 출력 

소프트맥스 함수: 모든 z값을 모아 하나의 결과를 출력(사실 하나의 결과는 아니고 각 클래스==z개수 별 확률 출력/이 확률의 전체합이 1)  
렐루함수: 각 z별 하나의 z에 렐루값이 적용돼 z개수만큼 출력 EX)z값이 10개면 렐루값도 10개 (z가 0보다 작으면 0, 0보다 크면 z로 변환)
시그모이드 함수: 얘도 렐루처럼 작용(2개가 들어와야한다고 착각할 수 있지만 사실 이진 분류에서도 시그모이드 함수는 하나에만 적용됐고 나머지는 1-a를 했었음) -> 0~1의 값으로 변환


!!!!!!!!!!!!!!!!딥러닝에서 가중치를 업데이트하는 방법!!!!!!!!!!!!!!!!!
1. 순전파 (Forward Pass)
입력 → 은닉층들 → 출력층 → softmax → 예측값 계산

2. 손실 함수 계산
예측값 vs 정답 → 손실(loss) 계산   예: categorical crossentropy

3. 역전파 (Backward Pass)
출력층부터 시작해서 오차(손실)를 역으로 전달하며 각 층의 가중치에 대해 미분(기울기)**을 계산

4. 가중치 업데이트
계산된 기울기(gradient)를 가지고 ***모든 층의*** 가중치를 동시에 업데이트 (ex: SGD, Adam 같은 옵티마이저로)



-----------------딥러닝에서의 선형대수학--------------------------
DNN
28*28을 1차원화 한다면 (768,)임(세로벡터)-> 그런데 tensorflow는 (배치크기,입력차원)으로 표시하므로 샘플하나를 (1,768)로 표현됌(가로)
그리고 뉴런개수를 10개라 한다면 가중치는 (768,10)이 됨-> 따라서 행렬곱하면 (1,768)@(768,10)=(1,10)의 구조로 나오개 됨(행렬곱을 가중치가 뒤에)
더 나아가 배치크기 32라면 (32,768)@(768,10)=(32,10) 이고 여기에 절편을 더하게 된다면 절편개수는 뉴런개수이므로 (10,)가되고
절편이 더해진다면 브로드캐스팅으로 32개 행마다 (1,10)으로 변환되어 더해짐-> 최종(32,10)

RNN
